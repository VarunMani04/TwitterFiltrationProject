{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Imported Libraries & Setup**"
      ],
      "metadata": {
        "id": "uUj72n69LnXS"
      },
      "id": "uUj72n69LnXS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f77fff1",
      "metadata": {
        "id": "4f77fff1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns=50\n",
        "\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "tweets = pd.read_csv('PSUTweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e75355",
      "metadata": {
        "id": "77e75355"
      },
      "outputs": [],
      "source": [
        "# View Uploaded Data\n",
        "tweets.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning Dataset**"
      ],
      "metadata": {
        "id": "HaMGkTC3LsFt"
      },
      "id": "HaMGkTC3LsFt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f67b1bd",
      "metadata": {
        "id": "9f67b1bd"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    #Any Patters Can be Used Here\n",
        "    pattern1 = r'@[^ ]+'\n",
        "    pattern2 = r'https?://[A-Za-z0-9./]+'\n",
        "    pattern3 = r'\\'s'\n",
        "    pattern4 = r'\\#\\w+'\n",
        "    pattern5 = r'&amp '\n",
        "    pattern6 = r'[^A-Za-z\\s]'\n",
        "\n",
        "    combined_pattern = r'|'.join((pattern1,pattern2,pattern3,pattern4,pattern5,pattern6))\n",
        "    text = re.sub(combined_pattern, \"\", text).lower()\n",
        "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51914490",
      "metadata": {
        "scrolled": true,
        "id": "51914490"
      },
      "outputs": [],
      "source": [
        "#Cleaning Applied Here\n",
        "tweets[\"cleaned_tweet\"] = tweets[\"Tweet\"].apply(clean_text)\n",
        "#tweets[\"cleaned_tweet\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processing Dataset | Sorting Based on Polarity and Subjectivity**"
      ],
      "metadata": {
        "id": "RaLErWJ3L8ZG"
      },
      "id": "RaLErWJ3L8ZG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a530c7",
      "metadata": {
        "id": "27a530c7"
      },
      "outputs": [],
      "source": [
        "for row in tweets.itertuples():\n",
        "    tweet = tweets.at[row[0], 'cleaned_tweet']\n",
        "#run sentiment using TextBlob\n",
        "    analysis = TextBlob(tweet)\n",
        "#set value to dataframe\n",
        "    tweets.at[row[0], 'polarity'] = analysis.sentiment[0]\n",
        "    tweets.at[row[0], 'subjectivity'] = analysis.sentiment[1]\n",
        "#Scale Based on Polarity\n",
        "    if analysis.sentiment[0]>0:\n",
        "       tweets.at[row[0], 'Sentiment'] = \"Positive\"\n",
        "    elif analysis.sentiment[0]<0:\n",
        "       tweets.at[row[0], 'Sentiment'] = \"Negative\"\n",
        "    else:\n",
        "       tweets.at[row[0], 'Sentiment'] = \"Neutral\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7951511f",
      "metadata": {
        "id": "7951511f"
      },
      "outputs": [],
      "source": [
        "tweet_polarity = tweets[[\"Date\", \"cleaned_tweet\", \"polarity\", \"Sentiment\"]]\n",
        "tweet_polarity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visulization: Sentiments Over Time**"
      ],
      "metadata": {
        "id": "SxJD1GHyMNPy"
      },
      "id": "SxJD1GHyMNPy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7adf2a9",
      "metadata": {
        "id": "c7adf2a9"
      },
      "outputs": [],
      "source": [
        "CountSentimentTotal = tweet_polarity.groupby(['Sentiment'])['Sentiment'].count().reset_index(name=\"Count\")\n",
        "CountSentimentTotal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496cc07e",
      "metadata": {
        "id": "496cc07e"
      },
      "outputs": [],
      "source": [
        "CountSentimentPerDay = tweet_polarity.groupby(['Sentiment', 'Date'])['Sentiment'].count().reset_index(name=\"Count\")\n",
        "CountSentimentPerDay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3aaaca1",
      "metadata": {
        "id": "d3aaaca1"
      },
      "outputs": [],
      "source": [
        "fig1 = px.line(\n",
        "CountSentimentPerDay,\n",
        "x= \"Date\",\n",
        "y = \"Count\",\n",
        "title = \"Sentiments on Twitter for PSU over time\",\n",
        "color = \"Sentiment\",\n",
        "labels = {\n",
        "    \"date\" : \"Date\",\n",
        "    \"Count\" : \"Number of Tweets\"\n",
        "},\n",
        "color_discrete_sequence=px.colors.qualitative.Set1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03f0959e",
      "metadata": {
        "id": "03f0959e",
        "outputId": "efe61941-6812-4714-fe58-41448a30c17d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-51928c2370db>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'fig1' is not defined"
          ]
        }
      ],
      "source": [
        "fig1"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}